{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d616825e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "train.csv not found; check your train_paths list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# If train data not found, stop the program with an error\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain.csv not found; check your train_paths list.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# === Convert 'log_price' to 'price' if 'log_price' column exists ===\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Because we want to predict actual price, not log(price)\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_price\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m train\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: train.csv not found; check your train_paths list."
     ]
    }
   ],
   "source": [
    "# === Import required libraries ===\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "# === Function to try multiple file paths and load the CSV ===\n",
    "def try_read(paths):\n",
    "    # Loop over the list of possible paths\n",
    "    for p in paths:\n",
    "        # Check if file exists at this path\n",
    "        if os.path.exists(p):\n",
    "            print(\"Loading:\", p)\n",
    "            # Load and return the CSV as DataFrame\n",
    "            return pd.read_csv(p)\n",
    "    # If none of the paths exist, return None\n",
    "    return None\n",
    "\n",
    "# === Possible file paths for train.csv and test.csv ===\n",
    "train_paths = [\n",
    "    \"C:/Users/alanm/Downloads/Predicting-Airbnb-List-Prices/train-data/train.csv\",  # example user path\n",
    "    \"./train.csv\",\n",
    "    \"./input/train.csv\",\n",
    "    \"./data/train.csv\"\n",
    "]\n",
    "\n",
    "test_paths = [\n",
    "    \"C:/Users/alanm/Downloads/Predicting-Airbnb-List-Prices/test-data/test.csv\",   # example user path\n",
    "    \"./test.csv\",\n",
    "    \"./input/test.csv\",\n",
    "    \"./data/test.csv\"\n",
    "]\n",
    "\n",
    "# === Load the training and test data ===\n",
    "train = try_read(train_paths)\n",
    "test = try_read(test_paths)  # test data is optional (for predictions)\n",
    "\n",
    "# If train data not found, stop the program with an error\n",
    "if train is None:\n",
    "    raise FileNotFoundError(\"train.csv not found; check your train_paths list.\")\n",
    "\n",
    "# === Convert 'log_price' to 'price' if 'log_price' column exists ===\n",
    "# Because we want to predict actual price, not log(price)\n",
    "if \"log_price\" in train.columns:\n",
    "    train[\"price\"] = np.exp(train[\"log_price\"])\n",
    "else:\n",
    "    # If no 'log_price' or 'price' column found, raise an error\n",
    "    if \"price\" not in train.columns:\n",
    "        raise ValueError(\"No 'price' or 'log_price' column found in train data.\")\n",
    "\n",
    "# === Define the target variable name ===\n",
    "TARGET = \"price\"\n",
    "\n",
    "# Get IDs for train and test datasets if available\n",
    "train_ids = train.get(\"id\")\n",
    "test_ids = test.get(\"id\") if test is not None and \"id\" in test.columns else None\n",
    "\n",
    "# === Prepare feature matrix X and target vector y ===\n",
    "# Drop columns not used as features: TARGET, 'log_price' (if exists), and 'id'\n",
    "X = train.drop([TARGET, \"log_price\", \"id\"] if \"id\" in train.columns else [TARGET, \"log_price\"], axis=1, errors=\"ignore\")\n",
    "y = train[TARGET].values  # target values as numpy array\n",
    "\n",
    "# Prepare test feature matrix (if test data is loaded)\n",
    "if test is not None:\n",
    "    X_test = test.drop([\"id\"] if \"id\" in test.columns else [], axis=1, errors=\"ignore\")\n",
    "else:\n",
    "    X_test = None\n",
    "\n",
    "# === Combine train and test features for consistent categorical encoding ===\n",
    "# This ensures categories are encoded consistently across train and test\n",
    "if X_test is not None:\n",
    "    combined = pd.concat([X, X_test], axis=0, ignore_index=True)\n",
    "else:\n",
    "    combined = X.copy().reset_index(drop=True)\n",
    "\n",
    "# === Encode categorical variables as integers ===\n",
    "for col in combined.columns:\n",
    "    if combined[col].dtype == \"object\" or combined[col].dtype.name == \"category\":\n",
    "        # Convert categories to integer codes\n",
    "        combined[col] = pd.factorize(combined[col].astype(str))[0]\n",
    "\n",
    "# === Split combined data back to train and test feature sets ===\n",
    "X = combined.iloc[: len(X)].reset_index(drop=True)\n",
    "if X_test is not None:\n",
    "    X_test = combined.iloc[len(X):].reset_index(drop=True)\n",
    "\n",
    "# === Fill missing values with a placeholder (-999) ===\n",
    "X = X.fillna(-999)\n",
    "if X_test is not None:\n",
    "    X_test = X_test.fillna(-999)\n",
    "\n",
    "# === Set up K-Fold cross-validation ===\n",
    "NFOLDS = 5  # number of folds\n",
    "kf = KFold(n_splits=NFOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize arrays to store out-of-fold predictions and test predictions\n",
    "oof = np.zeros(len(X))  # out-of-fold predictions for train data\n",
    "preds = np.zeros(len(X_test)) if X_test is not None else None  # test set predictions\n",
    "\n",
    "best_its = []  # to store best iteration for each fold\n",
    "\n",
    "# === Training with LightGBM using K-Fold cross-validation ===\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X, y), 1):\n",
    "    # Split data into training and validation sets for this fold\n",
    "    X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "    y_tr, y_val = y[tr_idx], y[val_idx]\n",
    "\n",
    "    # Initialize LightGBM regressor with chosen hyperparameters\n",
    "    model = LGBMRegressor(\n",
    "        n_estimators=10000,       # max number of boosting rounds\n",
    "        learning_rate=0.05,       # step size shrinkage\n",
    "        num_leaves=31,            # max number of leaves in one tree\n",
    "        subsample=0.8,            # fraction of data used per iteration\n",
    "        colsample_bytree=0.8,     # fraction of features used per iteration\n",
    "        random_state=42,\n",
    "        n_jobs=-1                 # use all CPU cores\n",
    "    )\n",
    "    \n",
    "    # Train model with early stopping on validation set to prevent overfitting\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric=\"rmse\",  # Root Mean Squared Error as metric\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=100),  # stop if no improvement for 100 rounds\n",
    "            lgb.log_evaluation(period=0)  # no periodic logging during training\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Get best iteration (number of trees) found by early stopping\n",
    "    best_it = model.best_iteration_ or model.n_estimators\n",
    "    best_its.append(best_it)\n",
    "\n",
    "    # Predict on validation data using best iteration and store out-of-fold predictions\n",
    "    oof[val_idx] = model.predict(X_val, num_iteration=best_it)\n",
    "\n",
    "    # Predict on test data and accumulate predictions for averaging\n",
    "    if X_test is not None:\n",
    "        preds += model.predict(X_test, num_iteration=best_it) / NFOLDS\n",
    "\n",
    "# === Calculate and print cross-validation RMSE ===\n",
    "cv_rmse = np.sqrt(mean_squared_error(y, oof))\n",
    "print(f\"CV RMSE (price): {cv_rmse:.6f}\")\n",
    "\n",
    "# === Train final model on entire training data using average best iteration ===\n",
    "final_best_it = int(np.mean(best_its))\n",
    "print(f\"Average best iteration across folds: {final_best_it}\")\n",
    "\n",
    "final_model = LGBMRegressor(\n",
    "    n_estimators=final_best_it,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# === Save submission file if test data is available ===\n",
    "if X_test is not None and test_ids is not None:\n",
    "    submission = pd.DataFrame({\n",
    "        \"id\": test_ids,\n",
    "        \"price\": preds  # predictions of actual price\n",
    "    })\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"Wrote submission.csv with price predictions.\")\n",
    "else:\n",
    "    print(\"No test set found; skipping submission.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
