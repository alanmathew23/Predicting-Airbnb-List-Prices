{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d616825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Import required libraries ===\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "# === Function to try multiple file paths ===\n",
    "def try_read(paths):\n",
    "    for p in paths:\n",
    "        if os.path.exists(p):\n",
    "            print(\"Loading:\", p)\n",
    "            return pd.read_csv(p)\n",
    "    return None\n",
    "\n",
    "# === File paths for train.csv and test.csv ===\n",
    "train_paths = [\n",
    "    \"C:/Users/alanm/.kaggle/input/train-data/train.csv\",  # Your actual file location\n",
    "    \"./train.csv\",\n",
    "    \"./input/train.csv\",\n",
    "    \"./data/train.csv\"\n",
    "]\n",
    "\n",
    "test_paths = [\n",
    "    \"C:/Users/alanm/.kaggle/input/test-data/test.csv\",   # Your actual file location\n",
    "    \"./test.csv\",\n",
    "    \"./input/test.csv\",\n",
    "    \"./data/test.csv\"\n",
    "]\n",
    "\n",
    "# === Load the data ===\n",
    "train = try_read(train_paths)\n",
    "test = try_read(test_paths)  # optional (used for prediction)\n",
    "\n",
    "if train is None:\n",
    "    raise FileNotFoundError(\"train.csv not found; check your train_paths list.\")\n",
    "\n",
    "# === Target variable ===\n",
    "TARGET = \"log_price\"\n",
    "train_ids = train.get(\"id\")\n",
    "test_ids = test.get(\"id\") if test is not None and \"id\" in test.columns else None\n",
    "\n",
    "# === Feature preprocessing ===\n",
    "X = train.drop([TARGET, \"id\"] if \"id\" in train.columns else [TARGET], axis=1, errors=\"ignore\")\n",
    "y = train[TARGET].values\n",
    "\n",
    "if test is not None:\n",
    "    X_test = test.drop([\"id\"] if \"id\" in test.columns else [], axis=1, errors=\"ignore\")\n",
    "else:\n",
    "    X_test = None\n",
    "\n",
    "# === Combine train + test for consistent encoding ===\n",
    "if X_test is not None:\n",
    "    combined = pd.concat([X, X_test], axis=0, ignore_index=True)\n",
    "else:\n",
    "    combined = X.copy().reset_index(drop=True)\n",
    "\n",
    "# === Encode categorical variables ===\n",
    "for col in combined.columns:\n",
    "    if combined[col].dtype == \"object\" or combined[col].dtype.name == \"category\":\n",
    "        combined[col] = pd.factorize(combined[col].astype(str))[0]\n",
    "\n",
    "# === Split data back ===\n",
    "X = combined.iloc[: len(X)].reset_index(drop=True)\n",
    "if X_test is not None:\n",
    "    X_test = combined.iloc[len(X):].reset_index(drop=True)\n",
    "\n",
    "# === Handle missing values ===\n",
    "X = X.fillna(-999)\n",
    "if X_test is not None:\n",
    "    X_test = X_test.fillna(-999)\n",
    "\n",
    "# === K-Fold cross-validation ===\n",
    "NFOLDS = 5\n",
    "kf = KFold(n_splits=NFOLDS, shuffle=True, random_state=42)\n",
    "oof = np.zeros(len(X))\n",
    "preds = np.zeros(len(X_test)) if X_test is not None else None\n",
    "best_its = []\n",
    "\n",
    "# === Training with LightGBM ===\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X, y), 1):\n",
    "    X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "    y_tr, y_val = y[tr_idx], y[val_idx]\n",
    "\n",
    "    model = LGBMRegressor(\n",
    "        n_estimators=10000,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric=\"rmse\",\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=100),\n",
    "            lgb.log_evaluation(period=0)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    best_it = model.best_iteration_ or model.n_estimators\n",
    "    best_its.append(best_it)\n",
    "\n",
    "    oof[val_idx] = model.predict(X_val, num_iteration=best_it)\n",
    "    if X_test is not None:\n",
    "        preds += model.predict(X_test, num_iteration=best_it) / NFOLDS\n",
    "\n",
    "# === Cross-validation result ===\n",
    "cv_rmse_log = np.sqrt(mean_squared_error(y, oof))\n",
    "print(f\"CV RMSE (log_price): {cv_rmse_log:.6f}\")\n",
    "\n",
    "# === Final model trained on all data ===\n",
    "final_best_it = int(np.mean(best_its))\n",
    "print(f\"Average best iteration across folds: {final_best_it}\")\n",
    "\n",
    "final_model = LGBMRegressor(\n",
    "    n_estimators=final_best_it,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# === Save submission if test is available ===\n",
    "if X_test is not None and test_ids is not None:\n",
    "    submission = pd.DataFrame({\n",
    "        \"id\": test_ids,\n",
    "        \"log_price\": preds  # predictions are in log scale\n",
    "    })\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"Wrote submission.csv with log_price predictions.\")\n",
    "else:\n",
    "    print(\"No test set found; skipping submission.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
